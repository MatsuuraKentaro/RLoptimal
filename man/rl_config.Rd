% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rl_config.R
\name{rl_config}
\alias{rl_config}
\title{Configuration of reinforcement learning}
\usage{
rl_config(
  iter = 500L,
  cores = 2L,
  gamma = 1,
  lr = 5e-05,
  train_batch_size = 10000L,
  model = rl_dnn_config(),
  sgd_minibatch_size = 200L,
  num_sgd_iter = 20L,
  ...
)
}
\arguments{
\item{iter}{A positive integer value. Number of iterations.}

\item{cores}{A positive integer value. Number of CPU cores used for learning.}

\item{gamma}{A positive numeric value. Discount factor of the Markov decision
process. Default is 1.0 (not discount).}

\item{lr}{A positive numeric value. Learning rate (default 5e-5). You can set
a learning schedule instead of a learning rate.}

\item{train_batch_size}{A positive integer value. Training batch size.
Deprecated on the new API stack.}

\item{model}{A list. Arguments passed into the policy model. See
\code{\link{rl_dnn_config}} for details.}

\item{sgd_minibatch_size}{A positive integer value. Total SGD batch size
across all devices for SGD. Deprecated on the new API stack.}

\item{num_sgd_iter}{A positive integer value. Number of SGD iterations in
each outer loop.}

\item{...}{Other settings for training(). See the arguments of the training()
function in the source code of RLlib.
https://github.com/ray-project/ray/blob/master/rllib/algorithms/algorithm_config.py
https://github.com/ray-project/ray/blob/master/rllib/algorithms/ppo/ppo.py}
}
\value{
A list of reinforcement learning configuration parameters
}
\description{
Mainly settings for the arguments of the training() function.
Not compatible with the new API stack introduced in Ray 2.10.0.
}
